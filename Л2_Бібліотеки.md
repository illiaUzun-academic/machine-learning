### Основні бібліотеки в машинному навчанні

#### 1. Вступ

- Короткий огляд інструментів для розробки систем машинного навчання.
- Значення бібліотек у спрощенні процесу розробки та впровадження моделей.

#### 2. NumPy

- Огляд бібліотеки NumPy.
- Основні можливості: робота з багатовимірними масивами, математичні функції.
- Приклади використання в задачах машинного навчання.

#### 3. Pandas

- Огляд бібліотеки Pandas.
- Робота з даними: читання, обробка, аналіз та візуалізація.
- Приклади використання для попередньої обробки даних.

#### 4. Matplotlib та Seaborn

- Візуалізація даних з Matplotlib.
- Розширені можливості візуалізації з Seaborn.
- Приклади створення графіків та діаграм для аналізу даних.

#### 5. Scikit-learn

- Огляд бібліотеки Scikit-learn.
- Представлення основних алгоритмів машинного навчання: класифікація, регресія, кластеризація.
- Приклади застосування для створення та оцінки моделей.

#### 6. TensorFlow та Keras

- Огляд TensorFlow: створення та тренування нейронних мереж.
- Використання Keras як високорівневого інтерфейсу для TensorFlow.
- Приклади побудови глибинних навчальних моделей.

#### 7. PyTorch

- Огляд бібліотеки PyTorch.
- Особливості та переваги: динамічні обчислювальні графи, інтуїтивний API.
- Приклади застосування для дослідження та розробки нейронних мереж.

#### 8. Додаткові інструменти

- Короткий огляд інших корисних бібліотек та інструментів: Plotly, Dask, XGBoost.
- Рекомендації щодо вибору інструментів залежно від конкретних задач.



### 1. Вступ

#### Короткий огляд інструментів для розробки систем машинного навчання

Машинне навчання (МН) - це галузь штучного інтелекту (ШІ), що займається розробкою алгоритмів, здатних навчатися та робити передбачення або рішення на основі даних. З розвитком цієї галузі з'явилося безліч інструментів та бібліотек, які спрощують розробку складних систем МН. Ці інструменти надають потужні можливості для обробки даних, статистичного аналізу, візуалізації, а також розробки та тренування моделей МН. Вони охоплюють широкий спектр потреб розробників, від базової підтримки лінійної алгебри до складних фреймворків для глибинного навчання.

#### Значення бібліотек у спрощенні процесу розробки та впровадження моделей

Бібліотеки машинного навчання відіграють ключову роль у спрощенні процесу розробки та впровадження моделей. Вони не лише надають стандартизовані та оптимізовані реалізації багатьох алгоритмів машинного навчання, але й забезпечують інтерфейси, які дозволяють розробникам зосередитися на рішенні конкретних задач, не заглиблюючись у складності реалізації алгоритмів. Це стимулює інновації та дозволяє швидко впроваджувати рішення в різних областях, від охорони здоров'я до фінансів.

Крім того, спільноти, що формуються навколо цих бібліотек, надають значну підтримку через документацію, навчальні матеріали та відкритий код. Це сприяє обміну знаннями та досвідом між розробниками, знижуючи поріг входження для новачків і сприяючи розвитку галузі як цілого.

Таким чином, бібліотеки машинного навчання є незамінним інструментом у сучасній аналітиці та розробці ШІ, відкриваючи перед дослідниками та розробниками широкі можливості для створення інноваційних та ефективних рішень.



### 2. NumPy

#### Огляд бібліотеки NumPy

NumPy (Numerical Python) є основною бібліотекою для наукових обчислень в Python. Вона надає підтримку для великих, багатовимірних масивів та матриць, разом з великою колекцією високорівневих математичних функцій для оперування цими масивами. Ефективність NumPy полягає в її здатності швидко виконувати операції над масивами, що робить її незамінною у великій кількості наукових та інженерних застосунків.

#### Основні можливості

- **Робота з багатовимірними масивами:** NumPy дозволяє створювати та маніпулювати масивами будь-якого розміру, від простих одновимірних до багатовимірних структур.
- **Математичні функції:** Включає широкий спектр математичних операцій, таких як алгебраїчні операції, статистичний аналіз, трансформації Фур'є та інші.

#### Приклади використання в задачах машинного навчання

##### Створення масивів

```python
import numpy as np

# Створення одновимірного масиву
arr_1d = np.array([1, 2, 3, 4, 5])
print("Одновимірний масив:", arr_1d)

# Створення двовимірного масиву
arr_2d = np.array([[1, 2, 3], [4, 5, 6]])
print("Двовимірний масив:\n", arr_2d)
```

##### Операції над масивами

```python
# Математичні операції
sum_arr = arr_1d + arr_1d
print("Сума масивів:", sum_arr)

# Статистичні функції
mean_value = np.mean(arr_1d)
print("Середнє значення масиву:", mean_value)
```

##### Використання в задачах машинного навчання

```python
# Нормалізація даних
data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
normalized_data = (data - np.min(data)) / (np.max(data) - np.min(data))
print("Нормалізовані дані:\n", normalized_data)

# Обчислення відстані між точками
point_a = np.array([1, 2, 3])
point_b = np.array([4, 5, 6])
distance = np.linalg.norm(point_a - point_b)
print("Відстань між точками:", distance)
```



### 3. Pandas

#### Огляд бібліотеки Pandas

Pandas — це високорівнева бібліотека Python, яка надає широкі можливості для аналізу даних. Вона дозволяє легко маніпулювати структурами даних, такими як датафрейми та серії, забезпечуючи зручні інструменти для читання, очищення, дослідження та трансформації даних. Pandas інтегрується з іншими науковими бібліотеками Python, такими як NumPy і Matplotlib, що робить її незамінною у комплексному аналізі даних.

#### Робота з даними: читання, обробка, аналіз та візуалізація

Pandas робить легкою роботу з різноманітними форматами даних, такими як CSV, Excel, JSON, і надає багатий набір функцій для обробки та аналізу цих даних. З її допомогою можна виконувати такі задачі, як фільтрація даних, групування, агрегація, а також використовувати її для візуалізації даних з метою отримання інсайтів.

#### Приклади використання для попередньої обробки даних

##### Читання даних з CSV файлу

```python
import pandas as pd

# Читання даних з CSV файлу
df = pd.read_csv('data.csv')
print(df.head())  # Виведення перших п'яти рядків
```

##### Очищення даних

```python
# Видалення рядків з відсутніми даними
cleaned_df = df.dropna()

# Заміна відсутніх значень середнім значенням стовпця
df['column_name'].fillna(df['column_name'].mean(), inplace=True)
```

##### Трансформація даних

```python
# Конвертація типів даних
df['column_name'] = df['column_name'].astype('float64')

# Додавання нового стовпця, який є результатом математичної операції
df['new_column'] = df['column1'] + df['column2']
```

##### Групування та агрегація даних

```python
# Групування даних за певним стовпцем і обчислення середнього
grouped_df = df.groupby('column_name').mean()
```

##### Візуалізація даних

```python
import matplotlib.pyplot as plt

# Створення гістограми
df['column_name'].hist()
plt.show()

# Будівництво діаграми розсіювання
df.plot(kind='scatter', x='column1', y='column2')
plt.show()
```



### 4. Matplotlib та Seaborn

#### Візуалізація даних з Matplotlib

Matplotlib — це основна бібліотека для візуалізації даних у Python. Вона дозволяє створювати статичні, анімовані та інтерактивні візуалізації в Python. Matplotlib є дуже гнучкою бібліотекою, яка надає засоби для створення різноманітних графіків та діаграм.

#### Розширені можливості візуалізації з Seaborn

Seaborn побудована на основі Matplotlib і надає більш високорівневий інтерфейс для створення статистичних графіків. Seaborn спрощує багато звичайних завдань візуалізації, забезпечуючи інтерфейс для створення привабливих та інформативних статистичних графіків.

#### Приклади створення графіків та діаграм

##### Візуалізація з Matplotlib

```python
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.plot(x, y)
plt.title("Синусоїда")
plt.xlabel("x")
plt.ylabel("sin(x)")
plt.show()
```

Цей код створює простий лінійний графік функції синуса.

##### Візуалізація з Seaborn

```python
import seaborn as sns
import pandas as pd

# Припустимо, у нас є DataFrame pandas з назвами columns 'category' і 'value'
data = pd.DataFrame({
    'category': ['A', 'B', 'C', 'D'],
    'value': [10, 20, 15, 5]
})

sns.barplot(x='category', y='value', data=data)
plt.title("Стовпчикова діаграма")
plt.show()
```

Цей код створює стовпчикову діаграму, використовуючи Seaborn, яка показує значення для різних категорій.



### 5. Scikit-learn

#### Огляд бібліотеки Scikit-learn

Scikit-learn — це одна з найпопулярніших бібліотек машинного навчання для Python, яка підтримує як наглядове, так і ненаглядове навчання. Вона включає в себе широкий спектр алгоритмів, від простих до складних, що покривають більшість потреб аналізу даних. Scikit-learn відома своєю простотою у використанні, документацією високої якості та великою спільнотою. Її API є дуже зручним і послідовним, що робить процес навчання та розгортання моделей максимально ефективним.

#### Основні алгоритми машинного навчання в Scikit-learn

##### Класифікація

Для задач класифікації, де метою є передбачення категоріальних міток об'єктів, Scikit-learn пропонує алгоритми, такі як логістична регресія, k-найближчих сусідів (k-NN), машини опорних векторів (SVM) та багато інших.

##### Регресія

Для регресійних задач, де потрібно передбачити неперервні значення, використовуються такі алгоритми, як лінійна регресія, регресія на основі дерев рішень або ансамблеві методи (наприклад, випадкові ліси).

##### Кластеризація

Для ненаглядованого навчання і групування подібних об'єктів Scikit-learn пропонує алгоритми кластеризації, такі як k-середніх (k-means), спектральна кластеризація та DBSCAN.

#### Приклади застосування для створення та оцінки моделей

##### Класифікація з використанням логістичної регресії

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score

# Завантаження датасету
iris = load_iris()
X, y = iris.data, iris.target

# Розділення датасету на тренувальний та тестовий набори
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Створення та тренування моделі
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# Передбачення на тестових даних
predictions = model.predict(X_test)

# Оцінка моделі
accuracy = accuracy_score(y_test, predictions)
print("Точність моделі:", accuracy)
```

##### Кластеризація з використанням k-середніх

```python
from sklearn.cluster import KMeans
import numpy as np

# Генерація д

аних
X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])

# Створення моделі k-середніх
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)

# Передбачення кластерів для нових даних
predictions = kmeans.predict([[0, 0], [12, 3]])
print("Приналежність до кластерів:", predictions)

# Центри кластерів
print("Центри кластерів:", kmeans.cluster_centers_)
```



### 6. TensorFlow та Keras

#### Огляд TensorFlow

TensorFlow — це відкрита бібліотека машинного навчання, розроблена Google, для створення та тренування нейронних мереж. Вона дозволяє легко конструювати, тренувати та розгортати складні моделі глибинного навчання. TensorFlow підтримує як CPU, так і GPU, що забезпечує високу швидкість обчислень при роботі з великими наборами даних.

#### Використання Keras як високорівневого інтерфейсу для TensorFlow

Keras — це високорівневий API для нейронних мереж, що базується на TensorFlow, який забезпечує простоту використання та гнучкість. Keras робить розробку моделей глибинного навчання більш доступною, надаючи прості для розуміння абстракції та зручні інструменти для швидкого прототипування. Keras ідеально підходить для експериментів, дозволяючи легко перевіряти нові ідеї.

#### Приклади побудови глибинних навчальних моделей

##### Створення простої моделі нейронної мережі в Keras

```python
from tensorflow import keras
from tensorflow.keras import layers

# Створення моделі
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(784,)),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Компіляція моделі
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Вивід структури моделі
model.summary()
```

Цей код створює просту нейронну мережу з трьома шарами для класифікації зображень. Мережа містить два приховані шари з активаційною функцією ReLU та вихідний шар з активаційною функцією softmax для класифікації на 10 класів.

##### Тренування моделі

```python
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

# Завантаження та підготовка даних
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 784))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 784))
test_images = test_images.astype('float32') / 255

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# Тренування моделі
model.fit(train_images, train_labels, epochs=5, batch_size=128)
```

Цей код демонструє процес тренування моделі на датасеті MNIST, який містить зображення рукописних цифр. Модель тренується протягом 5 епох з розміром батча 128.

TensorFlow та Keras разом надають потужні та гнучкі інструменти для створення та тренування моделей

 глибинного навчання. Вони дозволяють швидко переходити від концепції до прототипу та розгортання, сприяючи інноваціям у галузі машинного навчання.



### 7. PyTorch

#### Огляд бібліотеки PyTorch

PyTorch — це відкрита бібліотека машинного навчання, розроблена Facebook's AI Research lab, яка забезпечує велику гнучкість і швидкість у процесі наукових досліджень та розробки. Вона широко використовується у галузі академічних досліджень та промисловості завдяки своїй здатності до швидкого прототипування ідеї та високому рівню оптимізації.

#### Особливості та переваги

- **Динамічні обчислювальні графи:** На відміну від інших бібліотек, які використовують статичні графи, PyTorch працює з динамічними обчислювальними графами, що робить його особливо гнучким при експериментуванні з моделями та дозволяє змінювати архітектуру моделі "на льоту" під час виконання коду.

- **Інтуїтивний API:** PyTorch має зрозумілий та легкий у використанні API, який спрощує процес розробки та тренування моделей глибинного навчання, роблячи його доступним навіть для початківців.

#### Приклади застосування для дослідження та розробки нейронних мереж

##### Створення та тренування простої нейронної мережі

```python
import torch
import torch.nn as nn
import torch.optim as optim

# Визначення моделі
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 128)  # 784 вхідних нейрона до 128 нейронів у прихованому шарі
        self.fc2 = nn.Linear(128, 10)  # 128 нейронів у прихованому шарі до 10 вихідних нейронів

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Ініціалізація моделі, оптимізатора та функції втрат
model = Net()
optimizer = optim.SGD(model.parameters(), lr=0.01)
loss_function = nn.CrossEntropyLoss()

# Дані для тренування (припустимо, що вже завантажені та підготовлені)
# train_data, train_targets

# Тренування моделі
for epoch in range(10):  # кількість епох
    for data, target in zip(train_data, train_targets):
        optimizer.zero_grad()   # обнулення градієнтів
        output = model(data)    # отримання виходу моделі
        loss = loss_function(output, target)  # обчислення втрат
        loss.backward()         # обчислення градієнтів
        optimizer.step()        # оновлення параметрів моделі


    print(f'Епоха {epoch}, Втрати: {loss.item()}')
```

Цей код демонструє базову структуру для створення, тренування та оцінки простої нейронної мережі з використанням PyTorch. Модель складається з двох повністю з'єднаних шарів і тренується з використанням оптимізатора SGD для класифікації.

PyTorch славиться своєю гнучкістю та зручністю при розробці експериментальних архітектур нейронних мереж, що робить його популярним вибором серед науковців та розробників, зацікавлених у передових дослідженнях у галузі штучного інтелекту та машинного навчання.



### 8. Додаткові інструменти

#### Plotly

- **Огляд:** Plotly — це бібліотека, що дозволяє створювати інтерактивні графіки та дашборди для вебу. Вона підтримує багато типів візуалізацій, включаючи лінійні графіки, стовпчикові діаграми, карти та багато іншого, дозволяючи користувачам взаємодіяти з даними в режимі реального часу.
- **Застосування:** Plotly чудово підходить для створення деталізованих візуалізацій даних для веб-застосунків та презентацій, а також для розвідувального аналізу даних, коли потрібно глибше занурення в дані через інтерактивність.

#### Dask

- **Огляд:** Dask — це гнучка бібліотека для паралельних обчислень в Python. Вона дозволяє масштабувати роботу з NumPy, Pandas та Scikit-learn для роботи з великими датасетами, які не вміщуються в пам'ять одного комп'ютера.
- **Застосування:** Dask ідеально підходить для обробки великих даних і складних обчислень, які вимагають високої продуктивності та масштабованості, зокрема для задач обробки зображень, великих датасетів і паралельних обчислень.

#### XGBoost

- **Огляд:** XGBoost (eXtreme Gradient Boosting) — це ефективна реалізація алгоритму градієнтного бустингу, яка використовується для задач класифікації, регресії та ранжування. Вона забезпечує високу швидкість виконання та продуктивність.
- **Застосування:** XGBoost широко застосовується у змаганнях з аналізу даних і машинного навчання, таких як Kaggle, завдяки своїй високій ефективності і здатності до генерації дуже точних моделей. Вона підходить для широкого спектру задач, від кредитного скорингу до прогнозування попиту.

#### Рекомендації щодо вибору інструментів залежно від конкретних задач

- **Для інтерактивних візуалізацій:** Вибирайте Plotly, якщо потрібні багатофункціональні та інтерактивні візуалізації для веб-застосунків або презентацій.
- **Для обробки великих даних:** Використовуйте Dask, коли працюєте з датасетами, які перевищую

ть об'єм оперативної пам'яті, і потрібна масштабованість та паралелізм.
- **Для змагань з машинного навчання:** Розгляньте XGBoost як потужний інструмент для створення конкурентоспроможних моделей машинного навчання з високою точністю.

Вибір конкретного інструменту залежить від різних факторів, включаючи розмір і тип даних, конкретні вимоги до проекту, а також переваги розробника у термінах програмування та візуалізації.